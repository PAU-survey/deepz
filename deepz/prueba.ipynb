{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbcca7f4-f3ab-497f-993e-59a7e3362c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded path /nfs/pic.es/user/i/idazaper/deepz/deepz/arch_mdn.py\n",
      "# Galaxies 9133\n",
      "To store at:\n",
      "/data/astro/scratch/idazaper/deepz/redux/train/9/{net}_march11_ifold{ifold}.pt\n",
      "Alread run, skipping: /data/astro/scratch/idazaper/deepz/redux/train/9/enc_march11_ifold0.pt\n",
      "Alread run, skipping: /data/astro/scratch/idazaper/deepz/redux/train/9/enc_march11_ifold1.pt\n",
      "Alread run, skipping: /data/astro/scratch/idazaper/deepz/redux/train/9/enc_march11_ifold2.pt\n",
      "Alread run, skipping: /data/astro/scratch/idazaper/deepz/redux/train/9/enc_march11_ifold3.pt\n",
      "Alread run, skipping: /data/astro/scratch/idazaper/deepz/redux/train/9/enc_march11_ifold4.pt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected TensorOptions(dtype=unsigned char, device=cpu, layout=Strided, requires_grad=false (default), pinned_memory=false (default), memory_format=(nullopt)) (got TensorOptions(dtype=long int, device=cpu, layout=Strided, requires_grad=false (default), pinned_memory=false (default), memory_format=(nullopt)))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_424/3455764917.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mtrain_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrain_v_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mpz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphotoz_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0mpz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dx'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzb\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_424/3455764917.py\u001b[0m in \u001b[0;36mphotoz_all\u001b[0;34m(**config)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0minds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Inds_all should be a tensor in the first place.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mifold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpz_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mifold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out_fmt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'use_mdn'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_424/3455764917.py\u001b[0m in \u001b[0;36mpz_fold\u001b[0;34m(ifold, inds, out_fmt, use_mdn)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_pz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzbin_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mifold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deepz/deepz/loaders.py\u001b[0m in \u001b[0;36mget_loaders\u001b[0;34m(ifold, inds, data, Ntrain)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mix_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minds\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mifold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0mix_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mifold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected TensorOptions(dtype=unsigned char, device=cpu, layout=Strided, requires_grad=false (default), pinned_memory=false (default), memory_format=(nullopt)) (got TensorOptions(dtype=long int, device=cpu, layout=Strided, requires_grad=false (default), pinned_memory=false (default), memory_format=(nullopt)))"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Created at \n",
    "\n",
    "# =============================================================================\n",
    "# DOCS\n",
    "# =============================================================================\n",
    "\n",
    "\"\"\"train_data\n",
    "\"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "# IMPORTS\n",
    "# =============================================================================\n",
    "\n",
    "from IPython.core import debugger as ipdb\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import trainer_alpha\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import paus_sexp as paus_data\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import utils\n",
    "\n",
    "import local_settings\n",
    "import loaders\n",
    "\n",
    "sys.path.append('../code')\n",
    "# pretrain = True #False\n",
    "\n",
    "\"\"\"Constants\n",
    "\"\"\"\n",
    "# alpha\n",
    "alpha = 0.8\n",
    "\n",
    "# train set size\n",
    "Ntrain = 8000 #'all'   # Ntrain would have to be an input in the get_loaders function.\n",
    "\n",
    "# train set size\n",
    "Ntrain = 100 #'all'\n",
    "\n",
    "# verpretrain\n",
    "verpretrain = 3\n",
    "\n",
    "# paus data\n",
    "df_galcat = local_settings.galcat\n",
    "df_cosmos = local_settings.cosmos\n",
    "df_fa = local_settings.df_fa\n",
    "\n",
    "data = paus_data.paus(True, df_galcat, df_fa, df_cosmos)\n",
    "flux, flux_err, fmes, vinv, isnan, zbin, ref_id = data\n",
    "\n",
    "version = 2\n",
    "output_dir = Path(local_settings.redux_path) / str(version)\n",
    "\n",
    "# Other values collided with importing the code in a notebook...\n",
    "catnr = 0 #if len(sys.argv) == 1 else int(sys.argv[1])\n",
    "inds_all = np.loadtxt(local_settings.inds_large_v1_path)\n",
    "\n",
    "\n",
    "\n",
    "def train(pretrain_v_path, ifold, **config):\n",
    "    \"\"\"Train the networks for one fold.\n",
    "\n",
    "    :param pretrain_v_path: \n",
    "\n",
    "    :type pretrain_v_path: \n",
    "\n",
    "    :param ifold: ---\n",
    "\n",
    "    :type ifold:--\n",
    "\n",
    "    :param config:\n",
    "\n",
    "    :type config:\n",
    "\n",
    "    :return:\n",
    "\n",
    "    :rtype:\n",
    "\n",
    "    \"\"\"\n",
    "    #: verpretrain: is the version pretrain\n",
    "    verpretrain = config['verpretrain']\n",
    "\n",
    "    #: pretrain is pretrain\n",
    "    pretrain = config['pretrain']\n",
    "\n",
    "    # part is ?\n",
    "    part = 'mdn' if use_mdn else 'normal'\n",
    "\n",
    "    # Where to find the pretrained files.\n",
    "    path_base = pretrain_v_path + f'{verpretrain}' + '_{}_' + part + '.pt'\n",
    "\n",
    "    # Indices of the selected sources with flow information and \n",
    "    # ¿¿¿config['catnr']???.\n",
    "    inds = inds_all[config['catnr']][:len(flux)]\n",
    "    \n",
    "    #\n",
    "    enc, dec, net_pz = utils.get_nets(path_base, use_mdn, pretrain)\n",
    "    train_dl, test_dl, _ = loaders.get_loaders(ifold, inds, data, Ntrain)\n",
    "\n",
    "    K = (enc, dec, net_pz, train_dl, test_dl, use_mdn, config['alpha'], config['Nexp'], \\\n",
    "         config['keep_last'])\n",
    "\n",
    "    def params():\n",
    "        return chain(enc.parameters(), dec.parameters(), net_pz.parameters())\n",
    "   \n",
    "    wd = 1e-4\n",
    "    if True: #False: #False: #False: #True: #False: #True: #True: #False: #True: #False: #False: #True: #False: #True: #pretrain:\n",
    "        optimizer = optim.Adam(params(), lr=1e-3, weight_decay=wd)\n",
    "        trainer_alpha.train(optimizer, 100, *K)\n",
    "\n",
    "    print('main train function...')\n",
    "    optimizer = optim.Adam(params(), lr=1e-4, weight_decay=wd)\n",
    "    trainer_alpha.train(optimizer, 200, *K)\n",
    "    \n",
    "    optimizer = optim.Adam(params(), lr=1e-5, weight_decay=wd)\n",
    "    trainer_alpha.train(optimizer, 200, *K)\n",
    "\n",
    "    optimizer = optim.Adam(params(), lr=1e-6, weight_decay=wd)\n",
    "    trainer_alpha.train(optimizer, 200, *K)\n",
    "    \n",
    "    return enc, dec, net_pz\n",
    "\n",
    "\n",
    "def pz_fold(ifold, inds, out_fmt, use_mdn):\n",
    "    \"\"\"Estimate the photo-z for one fold.\"\"\"\n",
    "    \n",
    "    # Load network..\n",
    "    #model_dir = Path('/nfs/astro/eriksen/deepz/encmodels_data')\n",
    "    #path = str(model_dir/ f'{ifold}.pt')\n",
    "    \n",
    "    # Loading the networks...\n",
    "    net_base_path = out_fmt.format(ifold=ifold, net='{}')\n",
    "    enc, dec, net_pz = utils.get_nets(str(net_base_path), use_mdn)\n",
    "    enc.eval(), dec.eval(), net_pz.eval()\n",
    "    \n",
    "    _, test_dl, zbin_test = loaders.get_loaders(ifold, inds, data, Ntrain)\n",
    "\n",
    "   \n",
    "    assert isinstance(inds, torch.Tensor), 'This is required...'\n",
    " \n",
    "    # OK, this needs some improvement...\n",
    "    L = []\n",
    "    for Bflux, Bfmes, Bvinv, Bisnan, Bzbin in test_dl:\n",
    "        Bcoadd, touse = trainer_sexp.get_coadd(Bflux, Bfmes, Bvinv, Bisnan, alpha=1)\n",
    "        assert touse.all()\n",
    "            \n",
    "        # Testing training augmentation.            \n",
    "        feat = enc(Bcoadd)\n",
    "        Binput = torch.cat([Bcoadd, feat], 1)\n",
    "        pred = net_pz(Binput)\n",
    "        \n",
    "        zb_part = 0.001*pred.argmax(1).type(torch.float)\n",
    "        L.append(zb_part)\n",
    "\n",
    "    zb_fold = torch.cat(L).detach().cpu().numpy()\n",
    "    zs_fold = 0.001*zbin_test.type(torch.float)\n",
    "\n",
    "    refid_fold = ref_id[inds == ifold]\n",
    "    D = {'zs': zs_fold, 'zb': zb_fold, 'ref_id': refid_fold}\n",
    "    \n",
    "    part = pd.DataFrame(D)\n",
    "    part['ifold'] = ifold\n",
    "    #part = np.vstack([zs_fold, zb_fold]).T\n",
    "\n",
    "    return part\n",
    "\n",
    "\n",
    "def train_all(pretrain_v_path, **config):\n",
    "    \"\"\"Train all the folds.\"\"\"\n",
    "   \n",
    "    out_fmt = config['out_fmt']\n",
    "    for ifold in range(5):\n",
    "        test_path = str(out_fmt.format(net='enc', ifold=ifold))\n",
    "        if os.path.exists(test_path):\n",
    "            print('Alread run, skipping:', test_path)\n",
    "            continue\n",
    "            \n",
    "        print('Running for:', ifold)\n",
    "        t1 = time.time()\n",
    "        enc, dec, net_pz = train(pretrain_v_path, ifold, **config)\n",
    "        enc.eval()\n",
    "        dec.eval()\n",
    "        net_pz.train()\n",
    "        \n",
    "        print('time', time.time() - t1)\n",
    "       \n",
    "        #path = str(model_dir/ f'{ifold}.pt')\n",
    "        torch.save(enc.state_dict(), str(out_fmt.format(net='enc', ifold=ifold)))\n",
    "        torch.save(dec.state_dict(), str(out_fmt.format(net='dec', ifold=ifold)))\n",
    "        torch.save(net_pz.state_dict(),  str(out_fmt.format(net='netpz', ifold=ifold)))\n",
    "                   \n",
    "def photoz_all(**config):\n",
    "    \"\"\"Run the photo-z for all folds.\"\"\"\n",
    "                   \n",
    "    L = []\n",
    "    inds = inds_all[config['catnr']][:len(flux)]\n",
    "\n",
    "    inds = torch.Tensor(inds) # Inds_all should be a tensor in the first place.\n",
    "    for ifold in range(5):\n",
    "        L.append(pz_fold(ifold, inds, config['out_fmt'], config['use_mdn']))\n",
    "        \n",
    "    df = pd.concat(L)\n",
    "    df = df.set_index('ref_id')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "import trainer_sexp\n",
    "\n",
    "#model_dir = Path('models/v7')\n",
    "# Where we store the models based on the data...\n",
    "version = 9\n",
    "sim = 'fsps'\n",
    "\n",
    "def gen_conf():\n",
    "    for catnr in range(10):\n",
    "        for keep_last in [True]:\n",
    "            for alpha in [0.8]:\n",
    "#[0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "                yield catnr, keep_last, alpha\n",
    "\n",
    "# This code for running different configurations has been moved out into a notebook.\n",
    "if True: #True: #False: #False: #False: #True: #False:\n",
    "    #verpretrain = 3\n",
    "    #Ntrain = 8000\n",
    "    #catnr = 0\n",
    "\n",
    "    use_mdn = True\n",
    "    model_dir = Path('/data/astro/scratch/idazaper/deepz/redux/train') / str(version)\n",
    "\n",
    "    verpretrain = 8\n",
    "    Ntrain = 'all'\n",
    "    keep_last = False\n",
    "\n",
    "    label = 'march11'\n",
    "\n",
    "    for catnr, keep_last, alpha in gen_conf():\n",
    "           #for Ntrain in ['all']:\n",
    "        pretrain = False if verpretrain == 'no' else True\n",
    "        config = {'verpretrain': verpretrain, 'Ntrain': Ntrain, 'catnr': catnr, 'use_mdn': use_mdn,\n",
    "                  'Ntrain': Ntrain, 'pretrain': pretrain, 'keep_last': keep_last}\n",
    "\n",
    "        config['Nexp'] = 0\n",
    "        config['alpha'] = alpha\n",
    " \n",
    "            #    config['output_dir'] = output_dir\n",
    "#        out_fmt = 'pre{verpretrain}_alpha{alpha}_keep{keep_last}_catnr{catnr}'.format(**config)\n",
    "        out_fmt = '{net}_'+label+'_ifold{ifold}.pt'\n",
    "        out_fmt = str(model_dir / out_fmt)\n",
    "\n",
    "        config['out_fmt'] = out_fmt\n",
    "\n",
    "        print('To store at:')\n",
    "        print(out_fmt)\n",
    "\n",
    "        path = '/data/astro/scratch/idazaper/deepz/'\n",
    "        pretrain_v_path = os.path.join(path, 'redux/pretrain/v')\n",
    "        train_all(pretrain_v_path, **config) \n",
    "\n",
    "        pz = photoz_all(**config)\n",
    "        pz['dx'] = (pz.zb - pz.zs) / (1 + pz.zs)\n",
    "\n",
    "        sig68 = 0.5*(pz.dx.quantile(0.84) - pz.dx.quantile(0.16))\n",
    "        print('keep_last', keep_last, 'alpha', alpha, 'sig68', sig68)\n",
    "\n",
    "        fname = f'{label}'+'_catnr{catnr}.csv'.format(**config)\n",
    "        path_out = model_dir / fname\n",
    "\n",
    "        pz.to_csv(path_out) \n",
    "\n",
    "        # By now we only want to run one catalogue.\n",
    "\n",
    "        break\n",
    "    #cat_out = str(output_dir / f'pzcat_{catnr}_mdn.csv') #'/nfs/pic.es/user/e/eriksen/papers/deepz/sims/cats/pzcat_v65_mdn.csv'\n",
    "    #pz.to_csv(cat_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f89535c-6645-413a-8bbc-24b352c6ef5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lacegal",
   "language": "python",
   "name": "lacegal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
