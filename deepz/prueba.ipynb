{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbcca7f4-f3ab-497f-993e-59a7e3362c24",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (utils.py, line 19)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/data/astro/scratch/idazaper/miniconda3/envs/lacegal/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3457\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"/tmp/ipykernel_56/3455764917.py\"\u001b[0m, line \u001b[1;32m26\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    import trainer_alpha\n",
      "\u001b[0;36m  File \u001b[0;32m\"/nfs/pic.es/user/i/idazaper/deepz/deepz/trainer_alpha.py\"\u001b[0;36m, line \u001b[0;32m27\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    import utils\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/nfs/pic.es/user/i/idazaper/deepz/deepz/utils.py\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    SACAR ESTE PATH_BASE\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Created at \n",
    "\n",
    "# =============================================================================\n",
    "# DOCS\n",
    "# =============================================================================\n",
    "\n",
    "\"\"\"train_data\n",
    "\"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "# IMPORTS\n",
    "# =============================================================================\n",
    "\n",
    "from IPython.core import debugger as ipdb\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import trainer_alpha\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import paus_sexp as paus_data\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import utils\n",
    "\n",
    "import local_settings\n",
    "import loaders\n",
    "\n",
    "sys.path.append('../code')\n",
    "# pretrain = True #False\n",
    "\n",
    "\"\"\"Constants\n",
    "\"\"\"\n",
    "# alpha\n",
    "alpha = 0.8\n",
    "\n",
    "# train set size\n",
    "Ntrain = 8000 #'all'   # Ntrain would have to be an input in the get_loaders function.\n",
    "\n",
    "# train set size\n",
    "Ntrain = 100 #'all'\n",
    "\n",
    "# verpretrain\n",
    "verpretrain = 3\n",
    "\n",
    "# paus data\n",
    "df_galcat = local_settings.galcat\n",
    "df_cosmos = local_settings.cosmos\n",
    "df_fa = local_settings.df_fa\n",
    "\n",
    "data = paus_data.paus(True, df_galcat, df_fa, df_cosmos)\n",
    "flux, flux_err, fmes, vinv, isnan, zbin, ref_id = data\n",
    "\n",
    "version = 2\n",
    "output_dir = Path(local_settings.redux_path) / str(version)\n",
    "\n",
    "# Other values collided with importing the code in a notebook...\n",
    "catnr = 0 #if len(sys.argv) == 1 else int(sys.argv[1])\n",
    "inds_all = np.loadtxt(local_settings.inds_large_v1_path)\n",
    "\n",
    "\n",
    "\n",
    "def train(pretrain_v_path, ifold, **config):\n",
    "    \"\"\"Train the networks for one fold.\n",
    "\n",
    "    :param pretrain_v_path: \n",
    "\n",
    "    :type pretrain_v_path: \n",
    "\n",
    "    :param ifold: ---\n",
    "\n",
    "    :type ifold:--\n",
    "\n",
    "    :param config:\n",
    "\n",
    "    :type config:\n",
    "\n",
    "    :return:\n",
    "\n",
    "    :rtype:\n",
    "\n",
    "    \"\"\"\n",
    "    #: verpretrain: is the version pretrain\n",
    "    verpretrain = config['verpretrain']\n",
    "\n",
    "    #: pretrain is pretrain\n",
    "    pretrain = config['pretrain']\n",
    "\n",
    "    # part is ?\n",
    "    part = 'mdn' if use_mdn else 'normal'\n",
    "\n",
    "    # Where to find the pretrained files.\n",
    "    path_base = pretrain_v_path + f'{verpretrain}' + '_{}_' + part + '.pt'\n",
    "\n",
    "    # Indices of the selected sources with flow information and \n",
    "    # ¿¿¿config['catnr']???.\n",
    "    inds = inds_all[config['catnr']][:len(flux)]\n",
    "    \n",
    "    #\n",
    "    enc, dec, net_pz = utils.get_nets(path_base, use_mdn, pretrain)\n",
    "    train_dl, test_dl, _ = loaders.get_loaders(ifold, inds, data, Ntrain)\n",
    "\n",
    "    K = (enc, dec, net_pz, train_dl, test_dl, use_mdn, config['alpha'], config['Nexp'], \\\n",
    "         config['keep_last'])\n",
    "\n",
    "    def params():\n",
    "        return chain(enc.parameters(), dec.parameters(), net_pz.parameters())\n",
    "   \n",
    "    wd = 1e-4\n",
    "    if True: #False: #False: #False: #True: #False: #True: #True: #False: #True: #False: #False: #True: #False: #True: #pretrain:\n",
    "        optimizer = optim.Adam(params(), lr=1e-3, weight_decay=wd)\n",
    "        trainer_alpha.train(optimizer, 100, *K)\n",
    "\n",
    "    print('main train function...')\n",
    "    optimizer = optim.Adam(params(), lr=1e-4, weight_decay=wd)\n",
    "    trainer_alpha.train(optimizer, 200, *K)\n",
    "    \n",
    "    optimizer = optim.Adam(params(), lr=1e-5, weight_decay=wd)\n",
    "    trainer_alpha.train(optimizer, 200, *K)\n",
    "\n",
    "    optimizer = optim.Adam(params(), lr=1e-6, weight_decay=wd)\n",
    "    trainer_alpha.train(optimizer, 200, *K)\n",
    "    \n",
    "    return enc, dec, net_pz\n",
    "\n",
    "\n",
    "def pz_fold(ifold, inds, out_fmt, use_mdn):\n",
    "    \"\"\"Estimate the photo-z for one fold.\"\"\"\n",
    "    \n",
    "    # Load network..\n",
    "    #model_dir = Path('/nfs/astro/eriksen/deepz/encmodels_data')\n",
    "    #path = str(model_dir/ f'{ifold}.pt')\n",
    "    \n",
    "    # Loading the networks...\n",
    "    net_base_path = out_fmt.format(ifold=ifold, net='{}')\n",
    "    enc, dec, net_pz = utils.get_nets(str(net_base_path), use_mdn)\n",
    "    enc.eval(), dec.eval(), net_pz.eval()\n",
    "    \n",
    "    _, test_dl, zbin_test = loaders.get_loaders(ifold, inds, data, Ntrain)\n",
    "\n",
    "   \n",
    "    assert isinstance(inds, torch.Tensor), 'This is required...'\n",
    " \n",
    "    # OK, this needs some improvement...\n",
    "    L = []\n",
    "    for Bflux, Bfmes, Bvinv, Bisnan, Bzbin in test_dl:\n",
    "        Bcoadd, touse = trainer_sexp.get_coadd(Bflux, Bfmes, Bvinv, Bisnan, alpha=1)\n",
    "        assert touse.all()\n",
    "            \n",
    "        # Testing training augmentation.            \n",
    "        feat = enc(Bcoadd)\n",
    "        Binput = torch.cat([Bcoadd, feat], 1)\n",
    "        pred = net_pz(Binput)\n",
    "        \n",
    "        zb_part = 0.001*pred.argmax(1).type(torch.float)\n",
    "        L.append(zb_part)\n",
    "\n",
    "    zb_fold = torch.cat(L).detach().cpu().numpy()\n",
    "    zs_fold = 0.001*zbin_test.type(torch.float)\n",
    "\n",
    "    refid_fold = ref_id[inds == ifold]\n",
    "    D = {'zs': zs_fold, 'zb': zb_fold, 'ref_id': refid_fold}\n",
    "    \n",
    "    part = pd.DataFrame(D)\n",
    "    part['ifold'] = ifold\n",
    "    #part = np.vstack([zs_fold, zb_fold]).T\n",
    "\n",
    "    return part\n",
    "\n",
    "\n",
    "def train_all(pretrain_v_path, **config):\n",
    "    \"\"\"Train all the folds.\"\"\"\n",
    "   \n",
    "    out_fmt = config['out_fmt']\n",
    "    for ifold in range(5):\n",
    "        test_path = str(out_fmt.format(net='enc', ifold=ifold))\n",
    "        if os.path.exists(test_path):\n",
    "            print('Alread run, skipping:', test_path)\n",
    "            continue\n",
    "            \n",
    "        print('Running for:', ifold)\n",
    "        t1 = time.time()\n",
    "        enc, dec, net_pz = train(pretrain_v_path, ifold, **config)\n",
    "        enc.eval()\n",
    "        dec.eval()\n",
    "        net_pz.train()\n",
    "        \n",
    "        print('time', time.time() - t1)\n",
    "       \n",
    "        #path = str(model_dir/ f'{ifold}.pt')\n",
    "        torch.save(enc.state_dict(), str(out_fmt.format(net='enc', ifold=ifold)))\n",
    "        torch.save(dec.state_dict(), str(out_fmt.format(net='dec', ifold=ifold)))\n",
    "        torch.save(net_pz.state_dict(),  str(out_fmt.format(net='netpz', ifold=ifold)))\n",
    "                   \n",
    "def photoz_all(**config):\n",
    "    \"\"\"Run the photo-z for all folds.\"\"\"\n",
    "                   \n",
    "    L = []\n",
    "    inds = inds_all[config['catnr']][:len(flux)]\n",
    "\n",
    "    inds = torch.Tensor(inds) # Inds_all should be a tensor in the first place.\n",
    "    for ifold in range(5):\n",
    "        L.append(pz_fold(ifold, inds, config['out_fmt'], config['use_mdn']))\n",
    "        \n",
    "    df = pd.concat(L)\n",
    "    df = df.set_index('ref_id')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "import trainer_sexp\n",
    "\n",
    "#model_dir = Path('models/v7')\n",
    "# Where we store the models based on the data...\n",
    "version = 9\n",
    "sim = 'fsps'\n",
    "\n",
    "def gen_conf():\n",
    "    for catnr in range(10):\n",
    "        for keep_last in [True]:\n",
    "            for alpha in [0.8]:\n",
    "#[0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "                yield catnr, keep_last, alpha\n",
    "\n",
    "# This code for running different configurations has been moved out into a notebook.\n",
    "if True: #True: #False: #False: #False: #True: #False:\n",
    "    #verpretrain = 3\n",
    "    #Ntrain = 8000\n",
    "    #catnr = 0\n",
    "\n",
    "    use_mdn = True\n",
    "    model_dir = Path('/data/astro/scratch/idazaper/deepz/redux/train') / str(version)\n",
    "\n",
    "    verpretrain = 8\n",
    "    Ntrain = 'all'\n",
    "    keep_last = False\n",
    "\n",
    "    label = 'march11'\n",
    "\n",
    "    for catnr, keep_last, alpha in gen_conf():\n",
    "           #for Ntrain in ['all']:\n",
    "        pretrain = False if verpretrain == 'no' else True\n",
    "        config = {'verpretrain': verpretrain, 'Ntrain': Ntrain, 'catnr': catnr, 'use_mdn': use_mdn,\n",
    "                  'Ntrain': Ntrain, 'pretrain': pretrain, 'keep_last': keep_last}\n",
    "\n",
    "        config['Nexp'] = 0\n",
    "        config['alpha'] = alpha\n",
    " \n",
    "            #    config['output_dir'] = output_dir\n",
    "#        out_fmt = 'pre{verpretrain}_alpha{alpha}_keep{keep_last}_catnr{catnr}'.format(**config)\n",
    "        out_fmt = '{net}_'+label+'_ifold{ifold}.pt'\n",
    "        out_fmt = str(model_dir / out_fmt)\n",
    "\n",
    "        config['out_fmt'] = out_fmt\n",
    "\n",
    "        print('To store at:')\n",
    "        print(out_fmt)\n",
    "\n",
    "        path = '/data/astro/scratch/idazaper/deepz/'\n",
    "        pretrain_v_path = os.path.join(path, 'redux/pretrain/v')\n",
    "        train_all(pretrain_v_path, **config) \n",
    "\n",
    "        pz = photoz_all(**config)\n",
    "        pz['dx'] = (pz.zb - pz.zs) / (1 + pz.zs)\n",
    "\n",
    "        sig68 = 0.5*(pz.dx.quantile(0.84) - pz.dx.quantile(0.16))\n",
    "        print('keep_last', keep_last, 'alpha', alpha, 'sig68', sig68)\n",
    "\n",
    "        fname = f'{label}'+'_catnr{catnr}.csv'.format(**config)\n",
    "        path_out = model_dir / fname\n",
    "\n",
    "        pz.to_csv(path_out) \n",
    "\n",
    "        # By now we only want to run one catalogue.\n",
    "\n",
    "        break\n",
    "    #cat_out = str(output_dir / f'pzcat_{catnr}_mdn.csv') #'/nfs/pic.es/user/e/eriksen/papers/deepz/sims/cats/pzcat_v65_mdn.csv'\n",
    "    #pz.to_csv(cat_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f89535c-6645-413a-8bbc-24b352c6ef5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8000, 0.8000],\n",
       "         [0.8000, 0.8000]],\n",
       "\n",
       "        [[0.8000, 0.8000],\n",
       "         [0.8000, 0.8000]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "data = [[[1, 2],[3, 0]], [[1, 2],[4, 0]]]\n",
    "x_data = torch.tensor(data)\n",
    "0.8*torch.ones_like(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "130172ca-c5b1-42a3-a3ad-c1763a2aeabc",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (615174148.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_312/615174148.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    assert isinstance(data, torch.Tensor),\u001b[0m\n\u001b[0m                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "assert isinstance(data, torch.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0dedcdd7-9a3c-4761-9f9c-7fb5d8857bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 3],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.sum(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94172ac1-d384-4aa4-98dd-829d219d21d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "cat(tensors, dim=0, *, out=None) -> Tensor\n",
       "\n",
       "Concatenates the given sequence of :attr:`seq` tensors in the given dimension.\n",
       "All tensors must either have the same shape (except in the concatenating\n",
       "dimension) or be empty.\n",
       "\n",
       ":func:`torch.cat` can be seen as an inverse operation for :func:`torch.split`\n",
       "and :func:`torch.chunk`.\n",
       "\n",
       ":func:`torch.cat` can be best understood via examples.\n",
       "\n",
       "Args:\n",
       "    tensors (sequence of Tensors): any python sequence of tensors of the same type.\n",
       "        Non-empty tensors provided must have the same shape, except in the\n",
       "        cat dimension.\n",
       "    dim (int, optional): the dimension over which the tensors are concatenated\n",
       "\n",
       "Keyword args:\n",
       "    out (Tensor, optional): the output tensor.\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> x = torch.randn(2, 3)\n",
       "    >>> x\n",
       "    tensor([[ 0.6580, -1.0969, -0.4614],\n",
       "            [-0.1034, -0.5790,  0.1497]])\n",
       "    >>> torch.cat((x, x, x), 0)\n",
       "    tensor([[ 0.6580, -1.0969, -0.4614],\n",
       "            [-0.1034, -0.5790,  0.1497],\n",
       "            [ 0.6580, -1.0969, -0.4614],\n",
       "            [-0.1034, -0.5790,  0.1497],\n",
       "            [ 0.6580, -1.0969, -0.4614],\n",
       "            [-0.1034, -0.5790,  0.1497]])\n",
       "    >>> torch.cat((x, x, x), 1)\n",
       "    tensor([[ 0.6580, -1.0969, -0.4614,  0.6580, -1.0969, -0.4614,  0.6580,\n",
       "             -1.0969, -0.4614],\n",
       "            [-0.1034, -0.5790,  0.1497, -0.1034, -0.5790,  0.1497, -0.1034,\n",
       "             -0.5790,  0.1497]])\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.cat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932293c0-d8a6-4b03-8b9b-07282b009b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model_dir = Path('models/v7')\n",
    "# Where we store the models based on the data...\n",
    "version = 9\n",
    "sim = 'fsps'\n",
    "\n",
    "def gen_conf():\n",
    "    for catnr in range(10):\n",
    "        for keep_last in [True]:\n",
    "            for alpha in [0.8]:\n",
    "#[0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "                yield catnr, keep_last, alpha\n",
    "\n",
    "if True: #True: #False: #False: #False: #True: #False:\n",
    "    #verpretrain = 3\n",
    "    #Ntrain = 8000\n",
    "    #catnr = 0\n",
    "\n",
    "    use_mdn = True\n",
    "    model_dir = Path('/data/astro/scratch/idazaper/deepz/redux/train') / str(version)\n",
    "\n",
    "    verpretrain = 8\n",
    "    Ntrain = 'all'\n",
    "    keep_last = False\n",
    "\n",
    "    label = 'march11'\n",
    "\n",
    "    for catnr, keep_last, alpha in gen_conf():\n",
    "           #for Ntrain in ['all']:\n",
    "        pretrain = False if verpretrain == 'no' else True\n",
    "        config = {'verpretrain': verpretrain, 'Ntrain': Ntrain, 'catnr': catnr, 'use_mdn': use_mdn,\n",
    "                  'Ntrain': Ntrain, 'pretrain': pretrain, 'keep_last': keep_last}\n",
    "\n",
    "        config['Nexp'] = 0\n",
    "        config['alpha'] = alpha\n",
    " \n",
    "        out_fmt = '{net}_'+label+'_ifold{ifold}.pt'\n",
    "        out_fmt = str(model_dir / out_fmt)\n",
    "\n",
    "        config['out_fmt'] = out_fmt\n",
    "\n",
    "        print('To store at:')\n",
    "        print(out_fmt)\n",
    "\n",
    "        path = '/data/astro/scratch/idazaper/deepz/'\n",
    "        pretrain_v_path = os.path.join(path, 'redux/pretrain/v') #### AHHHH DIO CÓMO LO AGREGO?\n",
    "        train_all(pretrain_v_path, **config) \n",
    "\n",
    "        pz = photoz_all(**config)\n",
    "        pz['dx'] = (pz.zb - pz.zs) / (1 + pz.zs)\n",
    "\n",
    "        sig68 = 0.5*(pz.dx.quantile(0.84) - pz.dx.quantile(0.16))\n",
    "        print('keep_last', keep_last, 'alpha', alpha, 'sig68', sig68)\n",
    "\n",
    "        fname = f'{label}'+'_catnr{catnr}.csv'.format(**config)\n",
    "        path_out = model_dir / fname\n",
    "\n",
    "        pz.to_csv(path_out) \n",
    "\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f7f3f94-8462-4785-98c1-af590623c2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded path /nfs/pic.es/user/i/idazaper/deepz/deepz/arch_mdn.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from IPython.core import debugger as ipdb\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import trainer_alpha\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import paus_sexp as paus_data\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import utils\n",
    "\n",
    "import local_settings\n",
    "import loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7a125ce-f383-4c15-9abc-1529f0ce782c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To store at:\n",
      "/data/astro/scratch/idazaper/deepz/redux/train/9/{net}_march11_ifold{ifold}.pt\n",
      "/data/astro/scratch/idazaper/deepz/redux/train/9/enc_march11_ifold0.pt\n",
      "/data/astro/scratch/idazaper/deepz/redux/train/9/enc_march11_ifold1.pt\n",
      "/data/astro/scratch/idazaper/deepz/redux/train/9/enc_march11_ifold2.pt\n",
      "/data/astro/scratch/idazaper/deepz/redux/train/9/enc_march11_ifold3.pt\n",
      "/data/astro/scratch/idazaper/deepz/redux/train/9/enc_march11_ifold4.pt\n"
     ]
    }
   ],
   "source": [
    "version = 9\n",
    "label = 'march11'\n",
    "model_dir = Path('/data/astro/scratch/idazaper/deepz/redux/train') / str(version)\n",
    "out_fmt = '{net}_'+label+'_ifold{ifold}.pt'\n",
    "out_fmt = str(model_dir / out_fmt)\n",
    "\n",
    "\n",
    "\n",
    "print('To store at:')\n",
    "print(out_fmt)\n",
    "\n",
    "\n",
    "for ifold in range(5):\n",
    "    test_path = str(out_fmt.format(net='enc', ifold=ifold))\n",
    "    print(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0ad7907-81f3-41c8-9b3f-3befa20da70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen_conf():\n",
    "    for catnr in range(10):\n",
    "        for keep_last in [True]:\n",
    "            for alpha in [0.8]:\n",
    "#[0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "                yield catnr, keep_last, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9404de1-da6a-401c-991b-13bab816b147",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'catnr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_312/1730322728.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcatnr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_last\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'catnr' is not defined"
     ]
    }
   ],
   "source": [
    "catnr, keep_last, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dc177b6-91b0-43b1-9e69-4ef0af834314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 True 0.8\n",
      "1 True 0.8\n",
      "2 True 0.8\n",
      "3 True 0.8\n",
      "4 True 0.8\n",
      "5 True 0.8\n",
      "6 True 0.8\n",
      "7 True 0.8\n",
      "8 True 0.8\n",
      "9 True 0.8\n"
     ]
    }
   ],
   "source": [
    "for catnr, keep_last, alpha in gen_conf():\n",
    "    print(catnr, keep_last, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471e30ba-349c-4162-916f-bac842f32b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "\"\"\"Input\n",
    "\"\"\"\n",
    "# paus data\n",
    "df_galcat = local_settings.galcat\n",
    "df_cosmos = local_settings.cosmos\n",
    "df_fa = local_settings.df_fa\n",
    "data = paus_data.paus(True, df_galcat, df_fa, df_cosmos)\n",
    "\n",
    "# index\n",
    "inds_all = local_settings.inds_all\n",
    "\n",
    "\"\"\"Output\n",
    "\"\"\"\n",
    "version = 2\n",
    "output_dir = local_settings.output_dir\n",
    "\n",
    "\"\"\"Constants\n",
    "\"\"\"\n",
    "# alpha\n",
    "alpha = 0.8\n",
    "\n",
    "# train set size\n",
    "Ntrain = 100 #'all'\n",
    "\n",
    "# verpretrain\n",
    "verpretrain = 3\n",
    "\n",
    "# Other values collided with importing the code in a notebook...\n",
    "catnr = 0 #if len(sys.argv) == 1 else int(sys.argv[1])\n",
    "\n",
    "\n",
    "\"\"\"Config\n",
    "\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7855530e-2990-428f-9166-8f6cd184ea22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lacegal",
   "language": "python",
   "name": "lacegal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
